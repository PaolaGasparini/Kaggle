{"cells":[{"metadata":{},"cell_type":"markdown","source":"**iWildCam 2019 EDA\n**"},{"metadata":{},"cell_type":"markdown","source":"The aim of this competition is to classify animal species based on images collected. \nThe competition is using training data and test data from different regions, mainly Southwest America  and Northwest America. The target variable is \"category_id\""},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import gc\nimport os\nimport json\nimport logging\nimport datetime\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras import layers\nfrom keras.applications import DenseNet121\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.models import Sequential\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df=pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To check how many categories (target) there are:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.category_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Selecting one photo randomly for each category:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(25, 60))\nimgs = [np.random.choice(train_df.loc[train_df['category_id'] == i, 'file_name'], 4) for i in train_df.category_id.unique()]\nimgs = [i for j in imgs for i in j]\nlabels = [[i] * 4 for i in train_df.category_id.unique()]\nlabels = [i for j in labels for i in j]\nfor idx, img in enumerate(imgs):\n    ax = fig.add_subplot(14, 4, idx + 1, xticks=[], yticks=[])\n    im = Image.open(\"../input/train_images/\" + img)\n    plt.imshow(im)\n    ax.set_title(f'Label: {labels[idx]}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see that the category_id is the target variable.  Each category is an animal and the category 0 is \"empty\" that means no animal in the picture. \nI think useful variables are:\nDate: we can define day, month, hour, season to understand when it is more luckly to see a particular.\nLocation: maybe animals are location specific. \nSeq_num_frames: to see if  it is more luckly to have an empty category when there is only one frame.\n"},{"metadata":{},"cell_type":"markdown","source":"Let's do an assessment about what are the variables with highest correlation with the target. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset_c=train_df\nlabels = []\nvalues = []\nfor col in trainset_c.columns:\n    if col not in [ \"category_id\"] and trainset_c[col].dtype!='object':\n        labels.append(col)\n        values.append(np.corrcoef(trainset_c[col].values, trainset_c[\"category_id\"].values)[0,1])\ncorr_df = pd.DataFrame({'columns_labels':labels, 'corr_values':values})\ncorr_df = corr_df.sort_values(by='corr_values')\n \ncorr_df = corr_df[(corr_df['corr_values']>0.20) | (corr_df['corr_values']<-0.20)]\nind = np.arange(corr_df.shape[0])\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(10,6))\nrects = ax.barh(ind, np.array(corr_df.corr_values.values), color='gold')\nax.set_yticks(ind)\nax.set_yticklabels(corr_df.columns_labels.values, rotation='horizontal')\nax.set_xlabel(\"Correlation coefficient\")\nax.set_title(\"Correlation coefficient of the variables\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['category_id'].loc[train_df['category_id']]\nplt.figure(figsize=(12,10))\nsns.violinplot(x='category_id', y='seq_num_frames', data=train_df)\nplt.xlabel('category_id', fontsize=12)\nplt.ylabel('seq_num_frames', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see that if the catogory is empty the majority in this category has only one frame. The rest is quite well distributed. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import date, datetime\ntrain_df['date_time'] = pd.to_datetime(train_df['date_captured'], errors='coerce')\ntrain_df[\"year\"] = train_df['date_time'].dt.year\ntrain_df[\"month\"] = train_df['date_time'].dt.month\ntrain_df[\"day\"] = train_df['date_time'].dt.day\ntrain_df[\"hour\"] = train_df['date_time'].dt.hour\n\ntrain_df['season'] = train_df.month.map({1:4, 2:4, 3:1, 4:1, 5:1, 6:2, 7:2,8:2,9:3,10:3, 11:3,12:4})\n\n#1= spring \n#2=summer\n#3=autumn\n#4=winter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.ticker as ticker\ntrain_df['category_id'].loc[train_df['category_id']]\nplt.figure(figsize=(12,10))\nax= sns.violinplot(x='category_id', y='season', data=train_df)\nplt.xlabel('category_id', fontsize=12)\nplt.ylabel('season', fontsize=12)\n\n\n#ax = sns.boxplot(data = np.random.rand(20,30))\n\nax.yaxis.set_major_locator(ticker.MultipleLocator(1))\nax.yaxis.set_major_formatter(ticker.ScalarFormatter())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can clearly see that the category_id=22 is appearing only  during summer and autumn"},{"metadata":{},"cell_type":"markdown","source":"Rights_holder is also important because it could be that a specific photographer is specialised in some categories more than in others. Let's tranform this variable in 0 (Justin B.) or 1 (Erin..)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Rights_holderN'] = train_df.rights_holder.map({'Justin Brown':0, 'Erin Boydston':1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['category_id'] = train_df['category_id'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To create the best model it is important to split the training database into training and test set"},{"metadata":{},"cell_type":"markdown","source":"SOLUTION 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\n#Import from keras_preprocessing not from keras.preprocessing\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import regularizers, optimizers\nimport pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=32\nimg_size = 32\nnb_epochs = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.25)\ntrain_generator = train_datagen.flow_from_dataframe(\ndataframe = train_df,        \ndirectory = '../input/train_images',\nx_col = 'file_name', y_col = 'category_id',\nsubset=\"training\",\ntarget_size=(img_size,img_size),\nbatch_size=batch_size,\nclass_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nvalid_generator=train_datagen.flow_from_dataframe(\ndataframe=train_df,\ndirectory=\"../input/train_images/\",\nx_col=\"file_name\",\ny_col=\"category_id\",\nsubset=\"validation\",\nbatch_size=batch_size,\nseed=42,\nclass_mode=\"categorical\",\ntarget_size=(img_size,img_size))\n\n\ntest_datagen=ImageDataGenerator(rescale=1./255.)\n\ntest_generator=test_datagen.flow_from_dataframe(\ndataframe=test_df,\ndirectory=\"../input/test_images/\",\nx_col=\"file_name\",\ny_col=None,\nbatch_size=200,\nseed=42,\n\nclass_mode=None,\ntarget_size=(96,96))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=(32,32,3)))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(32, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(14, activation='softmax'))\nmodel.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\nSTEP_SIZE_TEST=test_generator.n//test_generator.batch_size\nmodel.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=10\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate_generator(generator=valid_generator,\nsteps=STEP_SIZE_TEST)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator.reset()\npred=model.predict_generator(test_generator,\nsteps=STEP_SIZE_TEST,\nverbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_class_indices=np.argmax(pred,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames=test_generator.filenames\nresults=pd.DataFrame({\"Filename\":filenames,\n                      \"Predictions\":predictions})\nresults.to_csv(\"results.csv\",index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SOLUTION 1 END"},{"metadata":{},"cell_type":"markdown","source":"PYTORCH applied"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nfrom keras.models import Sequential\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import regularizers, optimizers\nimport pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\n#Import from keras_preprocessing not from keras.preprocessing\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import regularizers, optimizers\nimport pandas as pd\nimport numpy as np\ndef append_ext(fn):\n    return fn+\".png\"\ntraindf=pd.read_csv(“./trainLabels.csv”,dtype=str)\ntestdf=pd.read_csv(\"./sampleSubmission.csv\",dtype=str)\ntraindf[\"id\"]=traindf[\"id\"].apply(append_ext)\ntestdf[\"id\"]=testdf[\"id\"].apply(append_ext)\ndatagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator( validation_split=0.2,\n                               rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"category_id\"]= str(train_df[\"category_id\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting Training set into trainset and validationset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator=train_datagen.flow_from_dataframe(\n                    dataframe=train_df,\n                    directory=\"../input/train_images/\",\n                    x_col=\"file_name\",\n                    y_col=\"category_id\",\n                    subset=\"training\",\n                    batch_size=200,\n                    seed=42,\n                    shuffle=True,\n                    class_mode=\"categorical\",\n                    target_size=(96,96))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_generator=train_datagen.flow_from_dataframe(\n                    dataframe=train_df,\n                    directory=\"../input/train_images/\",\n                    x_col=\"file_name\",\n                    y_col=\"category_id\",\n                    subset=\"validation\",\n                    batch_size=200,\n                    seed=42,\n                    shuffle=True,\n                    class_mode=\"categorical\",\n                    target_size=(96,96))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.mobilenet import MobileNet\nfrom keras.layers import Dense, Input, Dropout\nfrom keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SHAPE = Input(shape=(96,96, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nclass myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('acc')>0.998):\n      print(\"\\nReached 99.8% accuracy so cancelling training!\")\n      self.model.stop_training = True\n\ncallbacks = myCallback()\n\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(train_generator, training_labels, epochs=10, callbacks=[callbacks])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = False\nmodel = tf.keras.Sequential([base_model,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             tf.keras.layers.Dense(1024,activation='relu'),  \n                             tf.keras.layers.Dropout(0.2),\n                             tf.keras.layers.Dense(n_classes, activation='softmax')])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['acc']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = tf.keras.callbacks.ModelCheckpoint('weights-improvement.{epoch:02d}-{val_acc:.2f}.hdf5', monitor='val_loss', \n                                                verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS=10\nSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size + 1\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size + 1\nhistory = model.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=EPOCHS,\n                    callbacks=[checkpoint],          \n                    verbose=2\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we work on the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator=test_datagen.flow_from_dataframe(\n                dataframe=df_test,\n                directory=\"../input/test_images/\",\n                x_col=\"file_name\",\n                y_col=None,\n                batch_size=200,\n                seed=42,\n                shuffle=False,\n                class_mode=None,\n                target_size=(96,96))\nSTEP_SIZE_TEST=test_generator.n//test_generator.batch_size + 1\ntest_generator.reset()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prediction:"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=model.predict_generator(test_generator,\n                steps=STEP_SIZE_TEST,\n                verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmax(pred,axis=1)\npredicted_class_indices=np.argmax(pred,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.DataFrame({\"Id\":df_test.id,\n                      \"Predicted\":predictions})\nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"references:\nhttps://www.kaggle.com/artgor/iwildcam-basic-eda,\nhttps://www.kaggle.com/xhlulu/keras-cnn-starter-petfinder/,\nhttps://www.kaggle.com/bonhart/pytorch-eda-and-resnet, \nhttps://www.kaggle.com/rblcoder/cnn-in-tf-coursera-course-iwildcam-2019-mobilenet"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}