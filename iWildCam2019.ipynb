{"cells":[{"metadata":{},"cell_type":"markdown","source":"**iWildCam 2019 EDA\n**"},{"metadata":{},"cell_type":"markdown","source":"The aim of this competition is to classify animal species based on images collected. \nThe competition is using training data and test data from different regions, mainly Southwest America  and Northwest America. The target variable is \"category_id\""},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import gc\nimport os\nimport json\nimport logging\nimport datetime\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras import layers\nfrom keras.applications import DenseNet121\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.models import Sequential\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df=pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Selecting one photo randomly for each category:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(25, 60))\nimgs = [np.random.choice(train_df.loc[train_df['category_id'] == i, 'file_name'], 4) for i in train_df.category_id.unique()]\nimgs = [i for j in imgs for i in j]\nlabels = [[i] * 4 for i in train_df.category_id.unique()]\nlabels = [i for j in labels for i in j]\nfor idx, img in enumerate(imgs):\n    ax = fig.add_subplot(14, 4, idx + 1, xticks=[], yticks=[])\n    im = Image.open(\"../input/train_images/\" + img)\n    plt.imshow(im)\n    ax.set_title(f'Label: {labels[idx]}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see that the category_id is the target variable.  Each category is an animal and the category 0 is \"empty\" that means no animal in the picture. \nI think useful variables are:\nDate: we can define day, month, hour, season to understand when it is more luckly to see a particular.\nLocation: maybe animals are location specific. \nSeq_num_frames: to see if  it is more luckly to have an empty category when there is only one frame.\n"},{"metadata":{},"cell_type":"markdown","source":"Let's do an assessment about what are the variables with highest correlation with the target. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset_c=train_df\nlabels = []\nvalues = []\nfor col in trainset_c.columns:\n    if col not in [ \"category_id\"] and trainset_c[col].dtype!='object':\n        labels.append(col)\n        values.append(np.corrcoef(trainset_c[col].values, trainset_c[\"category_id\"].values)[0,1])\ncorr_df = pd.DataFrame({'columns_labels':labels, 'corr_values':values})\ncorr_df = corr_df.sort_values(by='corr_values')\n \ncorr_df = corr_df[(corr_df['corr_values']>0.20) | (corr_df['corr_values']<-0.20)]\nind = np.arange(corr_df.shape[0])\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(10,6))\nrects = ax.barh(ind, np.array(corr_df.corr_values.values), color='gold')\nax.set_yticks(ind)\nax.set_yticklabels(corr_df.columns_labels.values, rotation='horizontal')\nax.set_xlabel(\"Correlation coefficient\")\nax.set_title(\"Correlation coefficient of the variables\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['category_id'].loc[train_df['category_id']]\nplt.figure(figsize=(12,10))\nsns.violinplot(x='category_id', y='seq_num_frames', data=train_df)\nplt.xlabel('category_id', fontsize=12)\nplt.ylabel('seq_num_frames', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see that if the catogory is empty the majority in this category has only one frame. The rest is quite well distributed. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import date, datetime\ntrain_df['date_time'] = pd.to_datetime(train_df['date_captured'], errors='coerce')\ntrain_df[\"year\"] = train_df['date_time'].dt.year\ntrain_df[\"month\"] = train_df['date_time'].dt.month\ntrain_df[\"day\"] = train_df['date_time'].dt.day\ntrain_df[\"hour\"] = train_df['date_time'].dt.hour\n\ntrain_df['season'] = train_df.month.map({1:4, 2:4, 3:1, 4:1, 5:1, 6:2, 7:2,8:2,9:3,10:3, 11:3,12:4})\n\n#1= spring \n#2=summer\n#3=autumn\n#4=winter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.ticker as ticker\ntrain_df['category_id'].loc[train_df['category_id']]\nplt.figure(figsize=(12,10))\nax= sns.violinplot(x='category_id', y='season', data=train_df)\nplt.xlabel('category_id', fontsize=12)\nplt.ylabel('season', fontsize=12)\n\n\n#ax = sns.boxplot(data = np.random.rand(20,30))\n\nax.yaxis.set_major_locator(ticker.MultipleLocator(1))\nax.yaxis.set_major_formatter(ticker.ScalarFormatter())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can clearly see that the category_id=22 is appearing only  during summer and autumn"},{"metadata":{},"cell_type":"markdown","source":"Rights_holder is also important because it could be that a specific photographer is specialised in some categories more than in others. Let's tranform this variable in 0 (Justin B.) or 1 (Erin..)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Rights_holderN'] = train_df.rights_holder.map({'Justin Brown':0, 'Erin Boydston':1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import PIL\nfrom PIL import Image\nimport os, sys\n\n\npath = \"../input/train_images/\"\ndirs = os.listdir( path )\n\n\n\n\ndef resizetrain():\n    for item in dirs:\n        if os.path.isfile(path+item):\n            im = Image.open(path+item)\n            f, e = os.path.splitext(path+item)\n          \n            imResizeTrain = im.resize((32,32), Image.ANTIALIAS)\n         #   imResize.save(z + ' resized.jpg', 'JPEG', quality=90)\n\nresizetrain()\n\npathtest = \"../input/test_images/\"\ndirs = os.listdir( path )\n\ndef resizetest():\n    for item in dirs:\n        if os.path.isfile(path+item):\n            im = Image.open(path+item)\n            f, e = os.path.splitext(path+item)\n          \n            imResizeTest = im.resize((32,32), Image.ANTIALIAS)\n         #   imResize.save(z + ' resized.jpg', 'JPEG', quality=90)\n\nresizetest()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scale images"},{"metadata":{"trusted":true},"cell_type":"code","source":"imResizeTrain   =  imResizeTrain.astype('float32')\nimResizeTest =  imResizeTest.astype('float32')\nimResizeTrain /= 255.\nimResizeTest /= 255.\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator_df= pd.DataFrame()\ngenerator_df=  train_df[['category_id', 'id']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator_df['category_id']=str('category_id')\ngenerator_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    zca_whitening=False,  # apply ZCA whitening\n    zca_epsilon=1e-06,  # epsilon for ZCA whitening\n    rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n    shear_range=0.1,  # set range for random shear\n    zoom_range=0.1,  # set range for random zoom\n    channel_shift_range=0.,  # set range for random channel shifts\n    # set mode for filling points outside the input boundaries\n    fill_mode='nearest',\n    cval=0.,  # value used for fill_mode = \"constant\"\n    horizontal_flip=True,  # randomly flip images\n    vertical_flip=False,  # randomly flip images\n    # set rescaling factor (applied before any other transformation)\n    rescale=1/255.,\n    # set function that will be applied on each input\n    preprocessing_function=None,\n    # image data format, either \"channels_first\" or \"channels_last\"\n    data_format=None,\n    # fraction of images reserved for validation (strictly between 0 and 1)\n    validation_split=0.1\n)\n\ndef create_generator(subset):\n    return datagen.flow_from_dataframe(\n        generator_df, \n        imResizeTrain, \n        x_col='id',\n        y_col=str('category_id'), \n        has_ext=True,  # If image extension is given in x_col\n        target_size=(100, 100), \n        color_mode='rgb',\n        class_mode='categorical', \n        batch_size=128, \n        shuffle=True, \n        seed=2018,\n        subset=subset\n    )\n\ntrain_generator = create_generator('training')\nval_generator = create_generator('validation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.applications import DenseNet121","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"reference:\nhttps://www.kaggle.com/artgor/iwildcam-basic-eda\nhttps://www.kaggle.com/xhlulu/keras-cnn-starter-petfinder/"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}